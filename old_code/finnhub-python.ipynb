{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-19T04:51:44.163381Z",
     "start_time": "2024-06-19T04:51:43.288722Z"
    }
   },
   "source": [
    "import finnhub\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Setup client\n",
    "finnhub_client = finnhub.Client(api_key=os.environ['FINNHUB_KEY'])\n",
    "\n",
    "is_custom_date = os.getenv(\"CUSTOM_DATE\", 'False') == 'True'"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T04:52:05.256369Z",
     "start_time": "2024-06-19T04:52:05.139709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import bs4 as bs\n",
    "\n",
    "def get_tickers():\n",
    "    \"\"\"Method that gets the stock symbols from companies listed in the S&P 500\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    `tickers` : list\n",
    "        S&P 500 company symbols\n",
    "    \"\"\"\n",
    "    resp = requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find_all('table')[0]  # Grab the first table\n",
    "\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text.strip('\\n')\n",
    "        tickers.append(ticker)\n",
    "\n",
    "    return tickers"
   ],
   "id": "f52e011557789d9b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T04:52:06.496575Z",
     "start_time": "2024-06-19T04:52:05.998438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tickers = get_tickers()\n",
    "# tickers"
   ],
   "id": "eabe7cfbcd674b6c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T04:52:10.189726Z",
     "start_time": "2024-06-19T04:52:10.178763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "if is_custom_date:\n",
    "    # Instantiating and checking dates\n",
    "    start_date = \"2024-09-22\"\n",
    "    end_date = \"2024-02-22\"\n",
    "    \n",
    "    start_date_ = datetime.strptime(start_date, \"%Y-%m-%d\")  # datetime object\n",
    "    end_date_ = datetime.strptime(end_date, \"%Y-%m-%d\")  # datetime object\n",
    "    delta_date = abs((end_date_ - start_date_).days)  # number of days between 2 dates\n",
    "    \n",
    "    if start_date_ > end_date_:\n",
    "        raise Exception(\"'start_date' is after 'end_date'\")\n",
    "    \n",
    "    t = (datetime.now() - relativedelta(years=1))\n",
    "    \n",
    "    if start_date_ <= t:\n",
    "        raise Exception(\"'start_date' is older than 1 year. It doesn't work with the free version of FinnHub\")\n",
    "else:\n",
    "    # Default is to instantiate to 1 year prior\n",
    "    start_date = (datetime.now() - relativedelta(years=1)).strftime(\"%Y-%m-%d\")\n",
    "    end_date = datetime.now().strftime(\"%Y-%m-%d\")"
   ],
   "id": "fdeee9cd899eea8d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T04:52:11.266177Z",
     "start_time": "2024-06-19T04:52:11.254857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(start_date)\n",
    "print(end_date)"
   ],
   "id": "67c8f9f453489ac2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-19\n",
      "2024-06-19\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T04:53:47.323284Z",
     "start_time": "2024-06-19T04:53:27.710534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "folder_name = 'company_news'\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    \n",
    "for ticker in tickers:\n",
    "    # Pull all company news based on ticker list\n",
    "    # Need to use _from instead of from to avoid conflict\n",
    "    data = finnhub_client.company_news(ticker, _from=start_date, to=end_date)\n",
    "    df = pd.DataFrame.from_dict(data, orient='columns')\n",
    "    df.to_csv(f'{folder_name}/{ticker}.csv')"
   ],
   "id": "af4dd8fa2cfc367f",
   "outputs": [
    {
     "ename": "FinnhubAPIException",
     "evalue": "FinnhubAPIException(status_code: 429): API limit reached. Please try again later. Remaining Limit: 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFinnhubAPIException\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 9\u001B[0m\n\u001B[0;32m      4\u001B[0m     os\u001B[38;5;241m.\u001B[39mmakedirs(folder_name)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ticker \u001B[38;5;129;01min\u001B[39;00m tickers:\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;66;03m# Pull all company news based on ticker list\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# Need to use _from instead of from to avoid conflict\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mfinnhub_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompany_news\u001B[49m\u001B[43m(\u001B[49m\u001B[43mticker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_from\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart_date\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mend_date\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(data, orient\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     11\u001B[0m     df\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfolder_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mticker\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\astar\\sentiment-analysis\\webscrape_headlines\\venv\\Lib\\site-packages\\finnhub\\client.py:317\u001B[0m, in \u001B[0;36mClient.company_news\u001B[1;34m(self, symbol, _from, to)\u001B[0m\n\u001B[0;32m    316\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompany_news\u001B[39m(\u001B[38;5;28mself\u001B[39m, symbol, _from, to):\n\u001B[1;32m--> 317\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/company-news\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msymbol\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msymbol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    319\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrom\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m_from\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    320\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mto\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mto\u001B[49m\n\u001B[0;32m    321\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\astar\\sentiment-analysis\\webscrape_headlines\\venv\\Lib\\site-packages\\finnhub\\client.py:71\u001B[0m, in \u001B[0;36mClient._get\u001B[1;34m(self, path, **kwargs)\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get\u001B[39m(\u001B[38;5;28mself\u001B[39m, path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 71\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\astar\\sentiment-analysis\\webscrape_headlines\\venv\\Lib\\site-packages\\finnhub\\client.py:41\u001B[0m, in \u001B[0;36mClient._request\u001B[1;34m(self, method, path, **kwargs)\u001B[0m\n\u001B[0;32m     38\u001B[0m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_params(kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m\"\u001B[39m, {}))\n\u001B[0;32m     40\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_session, method)(uri, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 41\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\astar\\sentiment-analysis\\webscrape_headlines\\venv\\Lib\\site-packages\\finnhub\\client.py:46\u001B[0m, in \u001B[0;36mClient._handle_response\u001B[1;34m(response)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_handle_response\u001B[39m(response):\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m response\u001B[38;5;241m.\u001B[39mok:\n\u001B[1;32m---> 46\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m FinnhubAPIException(response)\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     49\u001B[0m         content_type \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mheaders\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mContent-Type\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mFinnhubAPIException\u001B[0m: FinnhubAPIException(status_code: 429): API limit reached. Please try again later. Remaining Limit: 0"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
